# Gu√≠a de pgvector - B√∫squeda Sem√°ntica

El sistema ahora implementa **b√∫squeda sem√°ntica avanzada** usando pgvector para PostgreSQL, permitiendo b√∫squedas inteligentes basadas en significado, no solo palabras clave.

## ¬øQu√© es pgvector?

**pgvector** es una extensi√≥n de PostgreSQL que permite:
- ‚úÖ **Almacenar vectores de embeddings** directamente en la base de datos
- ‚úÖ **B√∫squedas de similitud ultra-r√°pidas** con √≠ndices especializados
- ‚úÖ **Operadores vectoriales nativos** (cosine, L2, inner product)
- ‚úÖ **Escalabilidad** para millones de vectores

## Arquitectura Implementada

### **1. Modelos de Base de Datos con Vectores**

```sql
-- Embeddings de productos para b√∫squeda sem√°ntica
product_embeddings:
  - product_id: FK a products
  - content: texto combinado (nombre + descripci√≥n + categor√≠a)
  - embedding: vector[384] (sentence-transformers) o vector[1536] (OpenAI)
  - similarity search: <=> operator

-- Memoria de conversaciones con embeddings
conversation_memories:
  - customer_phone: identificador del cliente
  - memory_type: 'preference', 'order_history', 'complaint'
  - content + summary: contenido de la memoria
  - embedding: vector para b√∫squeda sem√°ntica
  - importance_score: relevancia de la memoria

-- Base de conocimientos con vectores
knowledge_base:
  - question + answer: preguntas frecuentes
  - category: tipo de conocimiento
  - embedding: vector del contenido
  - usage_count: estad√≠sticas de uso

-- Logs de b√∫squedas para analytics
search_logs:
  - query: b√∫squeda realizada
  - embedding: vector de la query
  - results_found: n√∫mero de resultados
  - search_time_ms: tiempo de respuesta
```

### **2. Modelos de Embeddings**

**Opci√≥n 1: Sentence Transformers (Recomendado para MVP)**
```python
Model: "sentence-transformers/all-MiniLM-L6-v2"
- Dimensiones: 384
- Velocidad: ~50ms por embedding
- Costo: GRATIS (local)
- Calidad: Excelente para espa√±ol
```

**Opci√≥n 2: OpenAI Embeddings (Producci√≥n)**
```python
Model: "text-embedding-ada-002"  
- Dimensiones: 1536
- Velocidad: ~200ms por embedding
- Costo: $0.0001 por 1K tokens
- Calidad: Superior
```

## B√∫squedas Sem√°nticas Implementadas

### **1. B√∫squeda de Productos Inteligente**

**Problema resuelto**: Cliente dice "algo vegetariano" y encuentra productos sin esa palabra exacta.

```python
# Cliente: "Quiero algo vegetariano y saludable"
# Encuentra: Patacones con Guacamole, Arepa de Queso
# Aunque no contengan la palabra "vegetariano"

results = vector_search_service.search_products_semantic(
    query="algo vegetariano y saludable",
    restaurant_id=1,
    limit=5,
    similarity_threshold=0.3
)
```

**Ejemplos de b√∫squedas inteligentes**:
- üîç `"algo barato"` ‚Üí encuentra productos bajo $10,000
- üîç `"comida t√≠pica"` ‚Üí encuentra Bandeja Paisa, Sancocho
- üîç `"para compartir"` ‚Üí encuentra platos grandes
- üîç `"sin carne"` ‚Üí encuentra opciones vegetarianas
- üîç `"algo refrescante"` ‚Üí encuentra bebidas y postres fr√≠os

### **2. Base de Conocimientos Inteligente**

**Problema resuelto**: Cliente pregunta de formas diferentes y obtiene la respuesta correcta.

```python
# Cliente: "¬øHasta qu√© hora atienden?"
# Encuentra: FAQ sobre horarios de atenci√≥n
# Aunque la pregunta registrada sea "¬øCu√°l es el horario?"

knowledge = vector_search_service.search_knowledge_base(
    query="hasta que hora atienden",
    restaurant_id=1
)
```

**Ejemplos de conocimiento inteligente**:
- ü§ñ `"cu√°nto demoran"` ‚Üí encuentra info de tiempos de entrega
- ü§ñ `"aceptan tarjeta"` ‚Üí encuentra info de m√©todos de pago  
- ü§ñ `"tienen vegano"` ‚Üí encuentra info de opciones vegetarianas
- ü§ñ `"d√≥nde est√°n ubicados"` ‚Üí encuentra direcci√≥n del restaurante

### **3. Memoria de Conversaciones Personalizada**

**Problema resuelto**: El agente recuerda preferencias y contexto del cliente.

```python
# Sistema recuerda: "Juan siempre pide sin cebolla"
# Pr√≥xima vez: "Para Juan, ¬øel pollo sin cebolla como siempre?"

memories = vector_search_service.search_conversation_memory(
    query="preferencias del cliente",
    customer_phone="+573001234567",
    restaurant_id=1
)
```

**Tipos de memoria**:
- üß† **Preferencias**: "Sin cebolla", "Extra picante", "Sin gluten"
- üß† **Historial**: "Siempre pide bandeja paisa los viernes"
- üß† **Quejas**: "Se quej√≥ de demora en entrega anterior"
- üß† **Cumplidos**: "Le gust√≥ mucho el sancocho"

## API Endpoints de B√∫squeda Sem√°ntica

### **Crear Embeddings**
```bash
POST /api/v1/vectors/embeddings/products/1
# Genera embeddings para todos los productos del restaurante

Response:
{
  "created": 15,
  "updated": 0, 
  "errors": 0
}
```

### **B√∫squeda Sem√°ntica de Productos**
```bash
POST /api/v1/vectors/search/products
{
  "query": "algo vegetariano y barato",
  "restaurant_id": 1,
  "limit": 5,
  "similarity_threshold": 0.3
}

Response:
{
  "query": "algo vegetariano y barato",
  "results": [
    {
      "product_id": 3,
      "name": "Arepa de Queso",
      "price": 6000,
      "similarity_score": 0.847,
      "category": "entradas"
    }
  ],
  "search_time_ms": 45,
  "total_results": 1
}
```

### **B√∫squeda en Base de Conocimientos**
```bash
POST /api/v1/vectors/search/knowledge
{
  "query": "cuanto demoran en entregar",
  "restaurant_id": 1
}

Response:
{
  "results": [
    {
      "question": "¬øCu√°l es el tiempo de entrega?",
      "answer": "Entregamos en 30-45 minutos en toda la ciudad",
      "similarity_score": 0.923,
      "category": "entrega"
    }
  ]
}
```

### **Crear Conocimiento**
```bash
POST /api/v1/vectors/knowledge/1
{
  "question": "¬øTienen opciones sin gluten?",
  "answer": "S√≠, tenemos arepas de ma√≠z y ensaladas que son naturalmente sin gluten.",
  "category": "menu_especial",
  "tags": ["sin gluten", "cel√≠aco", "opciones especiales"]
}
```

### **Almacenar Memoria de Cliente**
```bash
POST /api/v1/vectors/memory/123
{
  "memory_type": "preference",
  "content": "Cliente Juan siempre pide la bandeja paisa sin morcilla",
  "summary": "Sin morcilla en bandeja paisa",
  "importance_score": 0.8
}
```

### **Analytics de B√∫squedas**
```bash
GET /api/v1/vectors/analytics/1?days=7

Response:
{
  "analytics": {
    "common_queries": [
      {"query": "algo vegetariano", "count": 15, "avg_similarity": 0.782},
      {"query": "horario", "count": 12, "avg_similarity": 0.891}
    ],
    "performance": {
      "avg_search_time_ms": 45.2,
      "avg_embedding_time_ms": 52.1,
      "total_searches": 127
    }
  }
}
```

## Integraci√≥n con el Agente Conversacional

### **Prompt Mejorado con Vectores**

Cuando el agente recibe una consulta, ahora:

1. **Genera embedding** de la consulta del usuario
2. **Busca productos relevantes** sem√°nticamente  
3. **Busca conocimiento** relacionado en la base de datos
4. **Recupera memorias** espec√≠ficas del cliente
5. **Genera prompt mejorado** con contexto relevante

```python
# Ejemplo de prompt mejorado:
"""
MEN√ö DISPONIBLE:
[men√∫ completo...]

üéØ PRODUCTOS M√ÅS RELEVANTES PARA ESTA CONSULTA:
‚Ä¢ Arepa de Queso - $6,000 - Arepa tradicional rellena de queso (relevancia: 0.8)
‚Ä¢ Patacones con Guacamole - $12,000 - Patacones con guacamole fresco (relevancia: 0.7)

üìö INFORMACI√ìN RELEVANTE DEL RESTAURANTE:
P: ¬øTienen opciones vegetarianas?
R: S√≠, tenemos arepas de queso, patacones con guacamole, y ensaladas frescas.

üß† RECORDAR SOBRE ESTE CLIENTE:
‚Ä¢ Sin cebolla en todos los pedidos (preferencia)

‚ö° INSTRUCCI√ìN ESPECIAL: Usa la informaci√≥n de relevancia sem√°ntica arriba para dar respuestas m√°s precisas.
"""
```

## Configuraci√≥n y Setup

### **1. Instalar pgvector en PostgreSQL**

```bash
# Ubuntu/Debian
sudo apt install postgresql-15-pgvector

# macOS con Homebrew  
brew install pgvector

# Docker
docker run --name postgres-vector \
  -e POSTGRES_PASSWORD=password \
  -p 5432:5432 \
  -d pgvector/pgvector:pg15
```

### **2. Habilitar Extensi√≥n**

```sql
-- Como superuser en PostgreSQL
CREATE EXTENSION IF NOT EXISTS vector;

-- Verificar instalaci√≥n
SELECT * FROM pg_extension WHERE extname = 'vector';
```

### **3. Ejecutar Migraciones**

```bash
# Aplicar migraciones de embeddings
alembic upgrade head

# O ejecutar manualmente:
psql -d sales_agent_db -f alembic/versions/add_embeddings_tables.py
```

### **4. Configurar Modelo de Embeddings**

```env
# Opci√≥n 1: Sentence Transformers (gratis, local)
# No requiere configuraci√≥n adicional

# Opci√≥n 2: OpenAI Embeddings (pago, mejor calidad)  
OPENAI_API_KEY=sk-your_openai_api_key_here
```

### **5. Generar Embeddings Iniciales**

```bash
# Via API
curl -X POST http://localhost:8000/api/v1/vectors/embeddings/products/1

# Via setup autom√°tico
curl -X POST http://localhost:8000/setup
```

## Rendimiento y Optimizaci√≥n

### **√çndices de Rendimiento**
```sql
-- √çndice para b√∫squedas por similitud coseno
CREATE INDEX product_embeddings_cosine_idx 
ON product_embeddings USING ivfflat (embedding vector_cosine_ops);

-- √çndice para b√∫squedas L2  
CREATE INDEX product_embeddings_l2_idx
ON product_embeddings USING ivfflat (embedding vector_l2_ops);
```

### **M√©tricas de Rendimiento**
- **Generaci√≥n de embedding**: 50-200ms
- **B√∫squeda vectorial**: 10-50ms  
- **B√∫squeda total**: 60-250ms
- **Escalabilidad**: +100K vectores sin degradaci√≥n

### **Optimizaciones**
- **Cache de embeddings**: Para consultas frecuentes
- **Batch processing**: Para crear embeddings masivos
- **L√≠mites de similitud**: Filtrar resultados poco relevantes
- **√çndices especializados**: ivfflat para conjuntos grandes

## Casos de Uso Avanzados

### **1. Recomendaciones Personalizadas**
```python
# "Algo similar a lo que ped√≠ la semana pasada"
last_order_items = get_last_order_items(customer_phone)
embedding = combine_embeddings([item.embedding for item in last_order_items])
recommendations = vector_search(embedding, exclude=last_order_items)
```

### **2. B√∫squeda de Ingredientes**
```python
# "Sin l√°cteos" o "libre de gluten"
allergen_query = "sin lactosa sin gluten"
safe_products = search_products_semantic(allergen_query, filter_allergens=True)
```

### **3. An√°lisis de Sentimientos en Memorias**
```python
# Detectar clientes insatisfechos
negative_memories = search_memories("queja disgusto problema", sentiment="negative")
follow_up_customers = [m.customer_phone for m in negative_memories]
```

### **4. Clustering de Preferencias**
```python
# Agrupar clientes por preferencias similares
customer_embeddings = get_all_customer_preference_embeddings()
clusters = kmeans_clustering(customer_embeddings, n_clusters=5)
marketing_segments = assign_customers_to_segments(clusters)
```

## Monitoreo y Analytics

### **Dashboard de Vectores**
- **N√∫mero de embeddings**: Por restaurante y tipo
- **Consultas m√°s comunes**: Top 10 b√∫squedas sem√°nticas
- **Tiempo de respuesta**: Latencia P95, P99
- **Calidad de resultados**: Similarity scores promedio

### **Alertas Autom√°ticas**
- **Baja similaridad**: Cuando las b√∫squedas no encuentran resultados relevantes
- **Rendimiento degradado**: Cuando las b√∫squedas toman >500ms
- **Memoria llena**: Cuando se almacenan demasiadas memorias por cliente

### **M√©tricas de Negocio**
- **Conversi√≥n mejorada**: % de consultas que terminan en pedido
- **Satisfacci√≥n del cliente**: Based on conversation sentiment
- **Eficiencia del agente**: Tiempo promedio para resolver consultas

## Pr√≥ximas Mejoras

### **Implementaci√≥n Inmediata**
- [ ] **Embeddings multiling√ºes**: Soporte para ingl√©s
- [ ] **Filtros de categor√≠a**: B√∫squeda sem√°ntica por tipo de producto
- [ ] **Reranking inteligente**: Combinar similitud sem√°ntica con popularidad
- [ ] **A/B testing**: Comparar respuestas con/sin b√∫squeda sem√°ntica

### **Mediano Plazo**  
- [ ] **Fine-tuning**: Entrenar modelo espec√≠fico para comida colombiana
- [ ] **Embeddings de im√°genes**: B√∫squeda visual de platos
- [ ] **Temporal embeddings**: Considerar contexto temporal (hora, d√≠a)
- [ ] **Graph embeddings**: Relaciones entre productos, clientes, preferencias

### **Avanzado**
- [ ] **Federated search**: B√∫squeda cross-restaurante
- [ ] **Real-time embeddings**: Actualizaci√≥n continua de vectores
- [ ] **Embedding compression**: Reducir dimensionalidad sin perder calidad
- [ ] **Hybrid search**: Combinar vectorial + keyword + filtros

¬°El sistema de b√∫squeda sem√°ntica con pgvector est√° completamente implementado y listo para revolucionar la experiencia conversacional! üöÄüîç